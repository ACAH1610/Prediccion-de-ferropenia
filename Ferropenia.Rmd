---
title: "Ferropenia"
author: "Andrea"
date: "2024-03-21"
output:
  html_document:
    toc: yes
    toc_depth: 3
  word_document:
    toc: yes
    toc_depth: '3'
  output: null
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning=FALSE, message=FALSE}
#Librer?as necesarias
library(dplyr)
library(readxl)
library(ggplot2)
library(GGally)
library(kableExtra)
library(corrplot)
library(patchwork)
library(ggpubr)

library(tm)
library(stringr)
library(class)
library(gmodels)
library(ROCR)
library(caret)
```

# 1. Creación del dataset

## 1.1 Importación del excel

Partimos de un excel generado por el Sistema Informático del Laboratorio
(SIL) en el que se puso como condición que los pacientes tuvieran un VCM
por debajo del rango de normalidad, tanto bajo como muy bajo

```{r warning=FALSE, message=FALSE}

ferropenia = read_excel("~/aaaatalasemias/TFM/Ferropenia2.xls", 
col_types = c("text", "text", "numeric","text", "text", "text", "text", "text", "text", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "text", "text", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric"))
str (ferropenia)

```

## 1.2 Pasos a seguir para conseguir el Dataset objetivo:

### 1.2.1. Excluir a los pacientes que les falte alguna prueba necesaria para filtrar

Hematíes, hemoglobina, VCM, HCM, ADE, hematocrito, CHCM, PCR, ferritina,
IST, receptor soluble, además de la edad y sexo del paciente que serán
necesarios para tener en cuenta los valores de referencia.

```{r}
# Definimos las variables necesarias en un vector
pruebas_necesarias = c("HTIE", "HGB", "VCM", "HCM", "IDM", "HTCO", "CHCM", "PCR", "FERR", "ISTR")

# Nos quedamos solo con los pacientes que tengan todas las pruebas
ferropenia_filtrado = ferropenia[complete.cases(ferropenia[, pruebas_necesarias]), ]
```

### 1.2.2. Pasar todas las edades de días (x/365) y meses (x/12) a años

```{r}
# Hacemos una función para que la edad esté en años 
calcular_edad_years=function(numero, letra){
  if (letra == "mes" || letra == "meses") {
    edad_ajustada = numero / 12
  } else if (letra == "días") {
    edad_ajustada = numero / 365
  } else {
    edad_ajustada = numero  # Si no se especifica "mes" o "días", retornar el mismo valor
  }
  
  return(edad_ajustada)
  
}

# creamos una columna nueva con la edad ajustada
ferropenia_filtrado$edad_normalizada <- mapply(calcular_edad_years, 
                                        ferropenia_filtrado$`Edad(numero)`, 
                                        ferropenia_filtrado$`Edad(2parte)`)


```

### 1.2.3. Quedarnos con los pacientes hasta \>15 días -18 años

```{r}
#str(ferropenia_filtrado)
ferropenia_filtrado = filter(ferropenia_filtrado, edad_normalizada >= (15/365) & edad_normalizada <=18)

```

### 1.2.4. Excluir a los pacientes con una PCR\>1,5 para descartar posibles inflamación/infección

```{r}
ferropenia_filtrado = filter(ferropenia_filtrado, PCR<1.5)
```

### 1.2.5. Nos quitamos los pacientes duplicados

```{r}
#Seleccionamos los duplicados, quedandonos solo con el primero
duplicados <- duplicated(ferropenia_filtrado$NHC, fromLast = F)

# Filtramos el dataset
ferropenia_sin_duplicados <- ferropenia_filtrado[!duplicados, ]

```

### 1.2.6. Clasificar a los pacientes

Con las siguientes etiquetas en función de los valores de referencia: 

- Ferropenia latente: ferritina baja y IST normal, Hb normal. 

- Ferropenia funcional: ferritina baja y IST bajo, Hb normal. 

- Anemia ferropénica: ferritina baja y IST bajo, Hb baja. 

- Ausencia ferropenia: ferritina normal, IST normal.

Se añadirán columnas que nos indiquen si cada parámetro está alterado en función de los rangos de referencias por edad y sexo

```{r}
head(sort(ferropenia_sin_duplicados$edad_normalizada)) # veamos cual es la edad más baja que tenemos que incluir
head(sort(ferropenia_sin_duplicados$edad_normalizada, decreasing=T)) #edad más alta
```

```{r}
#Ferritina
#Rangos de referencia:
#0.1666667- 0.5 años= 15,3 – 375
#0.5 – 1 = 13.3-55.8
#1-16= 10.3-55.8
#>16 años (M): 18.7-102
#>16 años (F): 12-150
ferritina_function = function(ferritina, edad, sexo){
  if (edad >= 0.1666667 & edad<0.5 & ferritina< 15.3){
    return (1)
  } else if (edad >= 0.5 & edad<1 & ferritina< 13.3){
    return (1)
  } else if (edad >= 1 & edad<16 & ferritina< 10.3){
    return (1)
  }  else if (edad >= 15 & edad<= 18 & sexo== "M" & ferritina< 18.7)  {
    return (1)
  } else if (edad >= 15 & edad<= 18 & sexo== "F" & ferritina< 12 ) {
    return (1)
  } else {
    return (0)
  }
}
ferropenia_sin_duplicados$ferritina_baja = mapply(ferritina_function, ferropenia_sin_duplicados$FERR, ferropenia_sin_duplicados$edad_normalizada,ferropenia_sin_duplicados$`Sexo del Paciente`)
```

```{r}
#IST
#Rangos de referencia:
#0.1666667-0.25 años : 21 - 63
#0.25-0.4166667 años = 7 - 53
#0.4166667-0.5833333 años = 10 - 43
#0.5833333- 2 años = 6 – 38
#2 años - 12 años: 7 - 43
#12 años - 18 años: 18 - 46


IST_function = function(IST, edad, sexo){
  if (edad >= 0.1666667 & edad<0.25 & IST< 23){
    return(1)
  } else if (edad >= 0.25 & edad<0.4166667 & IST< 7){
    return(1)
  } else if (edad >= 0.4166667 & edad<0.5833333 & IST< 10){
    return (1)
  } else if (edad >= 0.5833333 & edad<2 & IST< 6){
    return (1)
  } else if (edad >= 2 & edad<12 & IST< 7){
    return (1)
  } else if (edad >= 12 & edad<= 18 & IST< 18)  {
    return (1)
  } else {
    return (0)
  }
}
ferropenia_sin_duplicados$IST_bajo = mapply(IST_function, ferropenia_sin_duplicados$ISTR, ferropenia_sin_duplicados$edad_normalizada,ferropenia_sin_duplicados$`Sexo del Paciente`)
```

```{r}
#Hemoglobina 
hemoglobina_function = function(hemoglobina, edad, sexo){
   if (edad >=0.1666667 & edad<0.25 & hemoglobina< 9){
    return(1)
  } else if (edad >= 0.25 & edad<0.5 & hemoglobina< 9.5){
    return(1)
  } else if (edad >= 0.5 & edad<2 & hemoglobina< 10.5){
    return (1)
  } else if (edad >= 2 & edad<6 & hemoglobina< 11.5){
    return (1)
  } else if (edad >= 6 & edad<12 & hemoglobina< 11.5){
    return (1)
  } else if (edad >= 12 & edad<= 18 & sexo== "M" & hemoglobina< 13)  {
    return (1)
  } else if (edad >= 12 & edad<= 18 & sexo== "F" & hemoglobina< 12 ) {
    return (1)
  } else {
    return (0)
  }
}
ferropenia_sin_duplicados$Hb_baja = mapply(hemoglobina_function, ferropenia_sin_duplicados$HGB, ferropenia_sin_duplicados$edad_normalizada,ferropenia_sin_duplicados$`Sexo del Paciente`)

#0.25 – 0.5 años: : 9,5 - 13,5
#0.5 – 2 años:  10,5 - 13,5
#2 - 6 años: 11,5 - 13,5
#6 - 12 años: 11,5 - 15,5
#12 - 18 años (M): 13 - 16
#12 - 18 años (F): 12 – 16
```

Hacemos la clasificacion en funcion de los parametros alterados 

- Si ferritina 1 , IST 0 , hemoglobina 0= Ferropenia latente 

- Si ferritina 1, IST 1 , hemoglobina 0 = Ferropenia funtional 

- Si ferritina 1 , IST 1, hemoglobina 1 = Anemia ferropenica 

- Si ferritina 0 , IST 0 = Ausencia de ferropenia

```{r}
clasificacion_function = function(ferritina, IST, hemoglobina){
  if (ferritina == 1 & IST==0 & hemoglobina==0){
    return("Ferropenia latente")
  } else if (ferritina == 1 & IST==1  & hemoglobina==0){
    return ("Ferropenia funcional")
  } else if (ferritina == 1 & IST==1  & hemoglobina==1){
    return ("Anemia ferropenica")
  } else if (ferritina == 0 & IST==0 ){
    return ("Ausencia de ferropenia")
  }else {
    return ("NA")
}
}
ferropenia_sin_duplicados$clasificacion= mapply(clasificacion_function, ferropenia_sin_duplicados$ferritina_baja, ferropenia_sin_duplicados$IST_bajo , ferropenia_sin_duplicados$Hb_baja)
```


### 1.2.7. Seleccionamos las variables de interés en nuestro estudio

```{r}
dataset= ferropenia_sin_duplicados[, c("Sexo del Paciente","edad_normalizada", "HTIE", "HGB", "VCM","HCM", "IDM", "CHCM", "HTCO", "clasificacion")]
dataset=filter(dataset, clasificacion != "NA")
```

# 2. Análisis descriptivo

## 2.1 Lectura de los datos

Las variables que vamos a utilizar:

```{r}
names(dataset)
```

"clasificacion" contiene las clases a predecir.

El número de observaciones según la clase es:

```{r}
kable(as.data.frame(table(dataset$clasificacion)),
      col.names= c("Clasificación", "Frecuencia"),
      align= "cc")
```

```{r}
pie(table(dataset$clasificacion))
```

Tenemos una distribución desbalanceada, hay que tener en cuenta para el tratamiento de los datos.

## 2.2 Exploración de los datos

### 2.2.1 Resumen de las variables:

```{r}
summary(dataset)
```

Nuestro dataset no necesita llevar a cabo la eliminación de datos
faltantes (NA) ya que se ha llevado a cabo en la realización del
dataset.

Por último vemos con tipo de variables estamos trabajando:

```{r}
str(dataset)
```

Podemos er que todas las variables son numéricas excepto el "Sexo del
Paciente" y la "clasificacion", que convertiremos a factor:

```{r}
dataset$`Sexo del Paciente`= as.factor(dataset$`Sexo del Paciente`)
dataset$clasificacion <- factor(dataset$clasificacion, 
                                levels = c("Anemia ferropenica", "Ferropenia funcional", "Ferropenia latente", "Ausencia de ferropenia"), 
                                labels = c("AF", "FF", "FL", "NF"))
dataset$`Sexo del Paciente` <- factor(dataset$`Sexo del Paciente`, 
                                levels = c("F", "M"), 
                                labels = c(1,0))
str(dataset)
```

Podemos ver lo primeros registros:

```{r}
head(dataset)
```

### 2.2.2 Gráficos exploratorios

#### Visualización de las variables cuantitativas en forma de boxplot

```{r}
#seleccionamos solo las variables cuantitativas
variables_cuantitativas <- dataset[, !(names(dataset) %in% c("Sexo del Paciente", "clasificacion"))]
colores= rainbow(ncol(variables_cuantitativas))
boxplot(variables_cuantitativas, col= colores)
```


Como se observa en el gráfico el rango de variabilidad entre variables
es muy grande por eso en algunos casos con rango de valores muy
estrechos queda reducida la caja a una linea. Esto nos indica que será
necesaria la normalización de los datos para que las variables tengan el
mismo peso.


#### Histogramas y boxplot en función de la clase y sexo:

```{r warning=FALSE, message=FALSE}
# Gráfico 1: Histograma
p1= ggplot(dataset, aes(x = edad_normalizada, color = `Sexo del Paciente`)) +
    geom_histogram(fill = "white", alpha = 0.5, position = "identity") +
    theme_classic()


# Gráfico 2: Gráfico de cajas
p2= ggplot(data = dataset, aes(x = clasificacion, y = edad_normalizada, col = `Sexo del Paciente`)) + 
    geom_boxplot()+
    theme_classic()
   
final_plot = ggarrange(p1, p2, legend = "top")
final_plot = annotate_figure(final_plot, top = text_grob("Edad", size =15))
final_plot

```


```{r warning=FALSE, message=FALSE}
# Gráfico 1: Histograma
p1= ggplot(dataset, aes(x = HTIE, color = `Sexo del Paciente`)) +
    geom_histogram(fill = "white", alpha = 0.5, position = "identity") +
    theme_classic()


# Gráfico 2: Gráfico de cajas
p2= ggplot(data = dataset, aes(x = clasificacion, y = HTIE, col = `Sexo del Paciente`)) + 
    geom_boxplot()+
    theme_classic()
   
final_plot = ggarrange(p1, p2, legend = "top")
final_plot = annotate_figure(final_plot, top = text_grob("Hematíes", size =15))
final_plot
```


```{r warning=FALSE, message=FALSE}
# Gráfico 1: Histograma
p1= ggplot(dataset, aes(x = HGB, color = `Sexo del Paciente`)) +
    geom_histogram(fill = "white", alpha = 0.5, position = "identity") +
    theme_classic()

# Gráfico 2: Gráfico de cajas
p2= ggplot(data = dataset, aes(x = clasificacion, y = HGB, col = `Sexo del Paciente`)) + 
    geom_boxplot()+
    theme_classic()
   
final_plot = ggarrange(p1, p2, legend = "top")
final_plot = annotate_figure(final_plot, top = text_grob("Hemoglobina", size =15))
final_plot
```


```{r warning=FALSE, message=FALSE}
# Gráfico 1: Histograma
p1=ggplot(dataset, aes(x = VCM, color = `Sexo del Paciente`)) +
    geom_histogram(fill = "white", alpha = 0.5, position = "identity") +
    theme_classic()


# Gráfico 2: Gráfico de cajas
p2=ggplot(data = dataset, aes(x = clasificacion, y = VCM, col = `Sexo del Paciente`)) + 
    geom_boxplot()+
    theme_classic()
  
final_plot <- ggarrange(p1, p2, legend = "top")
final_plot <- annotate_figure(final_plot, top = text_grob("VCM", size =15))
final_plot
```




```{r warning=FALSE, message=FALSE}
# Gráfico 1: Histograma
p1=ggplot(dataset, aes(x = HCM, color = `Sexo del Paciente`)) +
    geom_histogram(fill = "white", alpha = 0.5, position = "identity") +
    theme_classic()

# Gráfico 2: Gráfico de cajas
p2=ggplot(data = dataset, aes(x = clasificacion, y = HCM, col = `Sexo del Paciente`)) + 
    geom_boxplot()+
    theme_classic()
  
final_plot = ggarrange(p1, p2, legend = "top")
final_plot = annotate_figure(final_plot, top = text_grob("HCM", size =15))
final_plot
```

```{r warning=FALSE, message=FALSE}
# Gráfico 1: Histograma
p1=ggplot(dataset, aes(x = IDM, color = `Sexo del Paciente`)) +
    geom_histogram(fill = "white", alpha = 0.5, position = "identity") +
    theme_classic()

# Gráfico 2: Gráfico de cajas
p2=ggplot(data = dataset, aes(x = clasificacion, y = IDM, col = `Sexo del Paciente`)) + 
    geom_boxplot()+
    theme_classic()
  
final_plot = ggarrange(p1, p2, legend = "top")
final_plot = annotate_figure(final_plot, top = text_grob("ADE", size =15))
final_plot
```

```{r warning=FALSE, message=FALSE}
# Gráfico 1: Histograma
p1=ggplot(dataset, aes(x = CHCM, color = `Sexo del Paciente`)) +
    geom_histogram(fill = "white", alpha = 0.5, position = "identity") +
    theme_classic()

# Gráfico 2: Gráfico de cajas
p2=ggplot(data = dataset, aes(x = clasificacion, y = CHCM, col = `Sexo del Paciente`)) + 
    geom_boxplot()+
    theme_classic()
  
final_plot = ggarrange(p1, p2, legend = "top")
final_plot = annotate_figure(final_plot, top = text_grob("CHCM", size =15))
final_plot
```

```{r warning=FALSE, message=FALSE}
# Gráfico 1: Histograma
p1=ggplot(dataset, aes(x = HTCO, color = `Sexo del Paciente`)) +
    geom_histogram(fill = "white", alpha = 0.5, position = "identity") +
    theme_classic()

# Gráfico 2: Gráfico de cajas
p2=ggplot(data = dataset, aes(x = clasificacion, y = HTCO, col = `Sexo del Paciente`)) + 
    geom_boxplot()+
    theme_classic()
  
final_plot = ggarrange(p1, p2, legend = "top")
final_plot = annotate_figure(final_plot, top = text_grob("Hto", size =15))
final_plot
```

### 2.2.3 Búsqueda de correlación entre variables

Vemos también la matriz de correlación a para ver si hay relación entre los parámetros:

```{r}
cor(dataset[2:(ncol(dataset)-1)])
```

```{r}
corrplot(cor(dataset[2:(ncol(dataset)-1)]))
```
```{r}
ggpairs(dataset[2:(ncol(dataset)-1)])
```


Se ve que VCM y HCM una correlación elevada con un índice de correlación de 0.9339574 al igual que el Hto y la hemoglobina con índice de correlación del 0.9450355.
Se decide eliminar las variables con índice mayor de 0,85, en este caso el HCM y Hto. 

```{r}
dataset <- subset(dataset, select = -c(HTCO, HCM))
```

### 2.2.4 Análisis de componentes principales

Por último, se puede realizar una representación en dimensión reducida:
```{r}
PCA = prcomp(dataset[2:(ncol(dataset)-1)],center = TRUE,scale. = TRUE)
PCA.raw = PCA$x[,1:2]
plot(PCA.raw[,1], PCA.raw[,2],main = "Componentes principales",xlab = "PC1",ylab = "PC2",type="n")
points(PCA.raw[,1], PCA.raw[,2],col=as.factor(dataset$clasificacion))
```

No se ven grupos según la clasificación.

# 3. Preprocesamiento de datos

## 3.2 División del dataset en train y test

Hacemos la partición del dataset: 70% de los pacientes para el entrenamiento y el 30% para el testeo. 

```{r}
#Dejamos las variables categóricas como variables dummy
dummy <- model.matrix(~ `Sexo del Paciente` - 1, data = dataset)
dataset <- as.data.frame(cbind(dummy, dataset[2:ncol(dataset)]))
colnames(dataset)[colnames(dataset)== "`Sexo del Paciente`1"] = "Sexo_1"
colnames(dataset)[colnames(dataset)== "`Sexo del Paciente`0"] = "Sexo_0"
colnames(dataset)[colnames(dataset)== "clasificacion"] = "Clasificación"
str(dataset)
```



```{r}
n = nrow(dataset)
# Separamos los datos en Train y Test aleatoriamente
set.seed(29)
train = createDataPartition(dataset$Clasificación,p = 0.7, list = FALSE)
dataset.train = dataset[train,] #70%
dataset.test  = dataset[-train,] #30%

x.train= dataset.train[1:(ncol(dataset.train)-1)]
y.train= dataset.train[ncol(dataset.train)]
x.test= dataset.test[1:(ncol(dataset.train)-1)]
y.test= dataset.test[ncol(dataset.train)]
```


Comprobamos que la los casos están distribuidos equitativamente entre el dataset train y test
```{r}
porcentajes_train=round(table(dataset.train$Clasificación)/nrow(dataset.train)*100,2)
porcentajes_test=round(table(dataset.test$Clasificación)/nrow(dataset.test)*100,2)
```

```{r}
kable(rbind(porcentajes_train,porcentajes_test))
```


Efectivamente, las clases se encuentran proporcionados en cada partición.

## 3.1 Normalizamos 

Realizamos la normalización de los datos basándonos en los datos de entrenamiento y será esta normalización la que utilicemos para la partición test.

```{r}
preProcValues = preProcess(x.train, method = c("center", "scale"))

trainTransformed = predict(preProcValues, x.train)
testTransformed = predict(preProcValues, x.test)
dataset.test=cbind(testTransformed, y.test)
dataset.train= cbind(trainTransformed, y.train)
```


Vemos el resultado de la normalización:
```{r}
summary(trainTransformed)
#Volvemos a representar el boxplot de las variables cuantitativas del conjunto de entrenamiento
boxplot(trainTransformed, col= colores)
```



## 3.3 Balanceo de los datos de entrenamiento

Como hemos visto previamente, tenemos unos datos desbalanceados, por lo que vamos a utilizar la función SMOTE que crea nuevos casos sintéticos basados en los casos minoritarios.





# 4. Aplicación de cada algoritmo para la clasificación 

Realizaremos un 10-fold CrossValidation con 10 repeticiones en cada uno de los modelos.
```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10)
```

## 4.1 k-Nearest Neighbour 

```{r warning=FALSE, message=FALSE}
# Hiperparámetros
hiperparametros <- data.frame(k = c(1,5,10,15,20))

# Ajuste del modelo
set.seed(29)
modelo_knn <- train(Clasificación ~ ., data = dataset.train,
                    method = "knn",
                    tuneGrid = hiperparametros,
                    metric = "Accuracy",
                    trControl = fitControl)

modelo_knn

# Gráfica de la evolución de k
ggplot(modelo_knn) +
  labs(title = "Evolución del Accuracy del modelo KNN", x = "K") +
  theme_bw () +
  theme(plot.title = element_text(hjust = 0.5))

# Predicciones
knn_prediccion <- predict(modelo_knn, newdata = dataset.test[,-(ncol(dataset.test))],type = "raw")


# Evaluación
(mconfusion_knn <- confusionMatrix(knn_prediccion, dataset.test$Clasificación))
```



```{r}
resultados_knn <- data.frame( Modelo        = "KNN",
                              Parámetros    = "k=1",
                              Accuracy      = round(mconfusion_knn[["overall"]][["Accuracy"]], 3),
                              kappa         = round(mconfusion_knn[["overall"]][["Kappa"]],3),
                              Error_clasificación = round((1-mconfusion_knn[["overall"]][["Accuracy"]])*100,3),
                              AccuracyLower = round(mconfusion_knn[["overall"]][["AccuracyLower"]],3),
                              AccuracyUpper = round(mconfusion_knn[["overall"]][["AccuracyUpper"]],3)
                              )
resultados_knn
```

## 4.2 Naive Bayes

Esta técnica aplica el teorema de Bayes por lo que las variables deben ser cualitativas o discretas. 
Se deben discretizar (binning) las variables numéricas, se puede hacer previamente o dejar que lo realice el algoritmo, en este caso lo hará el algoritmo.

Se explorará la opción de activar o no laplace.


```{r warning=FALSE, message=FALSE}
# Hiperparámetros
hiperparametros <- expand.grid(usekernel = c(TRUE, FALSE),
                               fL = c(0,1),
                               adjust = c(1:5))
set.seed(29)

# Ajuste del modelo
set.seed(342)
( modelo_bayes = train(Clasificación ~ ., data = dataset.train,
                   method = "nb",
                   tuneGrid = hiperparametros,
                   metric = "Accuracy",
                   trControl = fitControl))


# Gráfica
ggplot(modelo_bayes) +
  labs(title = "Evolución del Accuracy del modelo Naive Bayes", x = "K") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```


```{r warning=FALSE, message=FALSE} 
# Predicciones
bayes_prediccion <- predict(modelo_bayes, dataset.test[1:(ncol(dataset.test)-1)])

# Evaluación
(mconfusion_Bayes <- confusionMatrix(bayes_prediccion, dataset.test$Clasificación))

```

```{r}
resultados_NaiveBayes <- data.frame( Modelo        = "Naive Bayes",
                              Parámetros    = "",
                              Accuracy      = round(mconfusion_Bayes[["overall"]][["Accuracy"]], 3),
                              kappa         = round(mconfusion_Bayes[["overall"]][["Kappa"]],3),
                              Error_clasificación = round((1-mconfusion_Bayes[["overall"]][["Accuracy"]])*100,3),
                              AccuracyLower = round(mconfusion_Bayes[["overall"]][["AccuracyLower"]],3),
                              AccuracyUpper = round(mconfusion_Bayes[["overall"]][["AccuracyUpper"]],3)
                              )
resultados_NaiveBayes
```

## 4.3 Artificial Neural Network

### 4.4.0 ANN-caret
```{r warning=FALSE, message=FALSE}
#hiperparametros 
hiperparametros = expand.grid(size = c(10, 20, 50, 80, 100, 120),
                               decay = c(0.0001, 0.00001, 0.1))



# Ajuste del modelo 
set.seed(29)

modelo_ann <- train(Clasificación ~ ., data = dataset.train,
                    method = "nnet",
                    tuneGrid = hiperparametros,
                    metric = "Accuracy",
                    trControl = fitControl,
                    MaxNWts = 2000,
                    trace = FALSE)
modelo_ann


# Gráfica
ggplot(modelo_ann, highlight = TRUE) +
  labs(title = "Evolución del accuracy del modelo ANN") +
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))

# Predicciones
predicciones_ann <- predict(modelo_ann, newdata = dataset.test[1:(ncol(dataset.test)-1)], type = "raw")

# Evaluación
res = table(predicciones_ann, dataset.test$Clasificación)
(mconfusion_ann = confusionMatrix(res))
```

```{r}
resultados_ann_caret = data.frame( Modelo        = "ANN caret",
                              Parámetros    = "",
                              Accuracy      = round(mconfusion_ann[["overall"]][["Accuracy"]], 3),
                              kappa         = round(mconfusion_ann[["overall"]][["Kappa"]],3),
                              Error_clasificación = round((1-mconfusion_ann[["overall"]][["Accuracy"]])*100,3),
                              AccuracyLower = round(mconfusion_ann[["overall"]][["AccuracyLower"]],3),
                              AccuracyUpper = round(mconfusion_ann[["overall"]][["AccuracyUpper"]],3)
                              )
resultados_ann_caret
```

Se explorarán las arquitecturas con una y dos capas ocultas: 1) con 15 nodos en una capa oculta, 2) 25 y 10 nodos en cada capa oculta.
Se usan los datos normalizados

```{r}
library(keras)
library(tensorflow)
library(tidyverse)
library(reticulate)
```

```{r}
#hacer matriz los datos de entrenamiento y test
dataset.train_ANN= as.matrix(dataset.train[1:ncol(dataset.train)-1])
dataset.test_ANN=as.matrix(dataset.test[1:ncol(dataset.test)-1])
dim(dataset.train_ANN)
dim(dataset.test_ANN)
```

```{r}

class_train = as.vector(dataset.train[[ncol(dataset.train)]])
class_test = as.vector(dataset.test[[ncol(dataset.test)]])

class_train= factor(class_train, levels= c("AF", "FF", "FL", "NF"), labels= c(1,2,3,4))
class_test= factor(class_test, levels= c("AF", "FF", "FL", "NF"), labels= c(1,2,3,4))

y_train = as.numeric(class_train) - 1 # integers from 0 to num_classes
y_test = as.numeric(class_test) - 1 # integers from 0 to num_classes
str(y_test)
str(y_train)
table(y_train)
table(y_test)
str(class_train)
```


```{r}
# Convertir las clases en matrices categóricas
y_train.cat = to_categorical(y_train)
y_test.cat = to_categorical(y_test)
str(y_train.cat)
str(y_test.cat)
```


```{r}
# Definir una función para convertir variables categóricas en matrices categóricas PORQUE NO FUNCIONABA TENSORFLOW (LO DEJO POR SI ACASO)
#to_categorical_custom <- function(y, num_classes = NULL) {
#  if (is.null(num_classes)) {
#    num_classes <- length(unique(y))
#  }
#  categorical_matrix <- matrix(0, nrow = length(y), ncol = num_classes)
#  for (i in 1:length(y)) {
#    categorical_matrix[i, y[i] + 1] <- 1  # Sumar 1 para que las clases vayan desde 1 hasta num_classes
#  }
#  return(categorical_matrix)
#}

# Convertimos la variable clasificación en una matriz categórica
#y_train_categorical = to_categorical_custom(y_train)
#y_test_categorical = to_categorical_custom(y_test)

#Comprobación 
#head(cbind(y_test, y_test_categorical))
```

### 4.3.1 ANN Modelo 1: 1 capa oculta

```{r}
#dataset.train_ANN
#dataset.test_ANN
#y_train_categorical 
#y_test_categorical
#y_train.cat
set.seed(29)
tf$random$set_seed(29)
# Establecemos cómo va a ser la red neuronal
input = layer_input(shape = c(ncol(dataset.train_ANN)))
# Modelo 1:
output = input %>%
layer_dense(units=15,activation="relu") %>%
layer_dense(units=4,activation="softmax")
dnn1 = keras_model(input, output)
summary(dnn1)

#Compilamos
dnn1 %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("acc")
)

#Entrenamos el modelo
set.seed(29)
history1 = dnn1 %>% fit(
dataset.train_ANN, y_train.cat,
epochs = 50,batch = 32,
validation_split = 0.2
)
plot(history1)

#testeo
yhat1 = predict(dnn1,dataset.test_ANN)
dim(yhat1)
length(y_test)
yhat.class1 = apply(yhat1,1,which.max)
yhat.class1 = yhat.class1 - 1 # integers desde 0

# Ajusta las dimensiones de las predicciones para que coincidan con las clases reales
yhat.class1_ajustado = factor(yhat.class1, levels = c(0,1,2,3))
kk<- table(yhat.class1_ajustado, y_test)
evalANN1 <- confusionMatrix(kk)
evalANN1
```

```{r}
resultados_ANN1 = data.frame( Modelo        = "ANN-1",
                              Parámetros    = "1 capas oculta",
                              Accuracy      = round(evalANN1[["overall"]][["Accuracy"]], 3),
                              kappa         = round(evalANN1[["overall"]][["Kappa"]],3),
                              Error_clasificación = round((1-evalANN1[["overall"]][["Accuracy"]])*100,3),
                              AccuracyLower = round(evalANN1[["overall"]][["AccuracyLower"]],3),
                              AccuracyUpper = round(evalANN1[["overall"]][["AccuracyUpper"]],3)
                              )
resultados_ANN1
```

### 4.3.2 ANN Modelo 2: 2 capas ocultas
```{r}
tf$random$set_seed(29)
set.seed(29)

# Modelo 2:
output = input %>%
layer_dense(units=25,activation="relu") %>%
layer_dense(units=10,activation="relu") %>%
layer_dense(units=4,activation="softmax")
dnn2 = keras_model(input, output)
summary(dnn2)

#Se compila 
dnn2 %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("acc")
)

# Se entrena 
history2 = dnn2 %>% fit(
dataset.train_ANN, y_train.cat,
epochs = 50,
batch = 32,
validation_split = 0.2
)
plot(history2)

# testeamos
yhat2=predict(dnn2,dataset.test_ANN)
yhat.class2=apply(yhat2,1,which.max)
yhat.class2 = yhat.class2 -1 # integers from 0

# Ajusta las dimensiones de las predicciones para que coincidan con las clases reales
yhat.class2_ajustado = factor(yhat.class2, levels = c(0,1,2,3))
kk= table(yhat.class2_ajustado, y_test)
evalANN2 = confusionMatrix(kk)
evalANN2
```

```{r}
resultados_ANN2 <- data.frame( Modelo        = "ANN-2",
                              Parámetros    = "2 capas ocultas",
                              Accuracy      = round(evalANN2[["overall"]][["Accuracy"]], 3),
                              kappa         = round(evalANN2[["overall"]][["Kappa"]],3),
                              Error_clasificación = round((1-evalANN2[["overall"]][["Accuracy"]])*100,3),
                              AccuracyLower = round(evalANN2[["overall"]][["AccuracyLower"]],3),
                              AccuracyUpper = round(evalANN2[["overall"]][["AccuracyUpper"]],3)
                              )
resultados_ANN2
```
Se obtienen mejores resultados con el modelo de 2 capas ocultas

```{r}
detach("package:keras", unload = TRUE)
detach("package:tensorflow", unload = TRUE)
```



## 4.4 Support Vector Machine

Probamos SVM-lineal y SVM-radial
Usamos los datos con las variables cuantitativas estandarizadas

### 4.4.1 SVM-lineal

```{r warning=FALSE, message=FALSE }
# Hiperparámetros
hiperparametros = data.frame(C = c(0.5,1,5,10,15,20,30,40,50))

# Ajuste del modelo 
set.seed(29)
modelo_svmlineal = train(Clasificación ~ ., data = dataset.train,
                          method = "svmLinear",
                          tuneGrid = hiperparametros,
                          metric = "Accuracy",
                          trControl = fitControl)

modelo_svmlineal


# Gráfico
ggplot(modelo_svmlineal) +
  labs(title = "Evolución del Accuracy del modelo SVMlineal") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))


# Predicciones
svmlineal_predicciones = predict(modelo_svmlineal, newdata = dataset.test[1:(ncol(dataset.test)-1)])

# Evaluación
(mconfusion_svmlineal = confusionMatrix(svmlineal_predicciones, dataset.test$Clasificación))

```


 
### 4.4.2 SVM-RBF o función gaussiana

```{r warning=FALSE, message=FALSE}
#Hiperparámetros
hiperparametros = expand.grid(sigma = c(0.5,1,2,3,5),
                               C = c(1,5,10,15,20,30))

# Ajuste del modelo 
set.seed(29)
modelo_svmradial = train(Clasificación ~ ., data = dataset.train,
                          method = "svmRadial",
                          tuneGrid = hiperparametros,
                          metric = "Accuracy",
                          trControl = fitControl)

modelo_svmradial


# Gráfico
ggplot(modelo_svmradial) +
  labs(title = "Evolución del Accuracy del modelo SVMRadial") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```


```{r}
# Predicciones
svmradial_predicciones = predict(modelo_svmradial, newdata = dataset.test[1:(ncol(dataset.test)-1)])

# Evaluación
(mconfusion_svmradial = confusionMatrix(svmradial_predicciones, dataset.test$Clasificación))

```

```{r}
resultados_SVM_radial <- data.frame( Modelo        = "SVM-Radial",
                              Parámetros    = "sigma = 3, C = 20",
                              Accuracy      = round(mconfusion_svmradial[["overall"]][["Accuracy"]], 3),
                              kappa         = round(mconfusion_svmradial[["overall"]][["Kappa"]],3),
                              Error_clasificación = round((1-mconfusion_svmradial[["overall"]][["Accuracy"]])*100,3),
                              AccuracyLower = round(mconfusion_svmradial[["overall"]][["AccuracyLower"]],3),
                              AccuracyUpper = round(mconfusion_svmradial[["overall"]][["AccuracyUpper"]],3)
                              )
resultados_SVM_radial
```

### 4.4.3 SVM-polynomial
```{r warning=FALSE, message=FALSE} 
# Hiperparámetros
hiperparametros = expand.grid(degree = c(2),
                               scale = c(0.1,0.2,0.3,0.5,0.7,1),
                               C = c(5,10,15,20,30,40,50,80))
# Ajuste del modelo 
set.seed(29)
modelo_svmpoly = train(Clasificación ~ ., data = dataset.train,
                          method = "svmPoly",
                          tuneGrid = hiperparametros,
                          metric = "Accuracy",
                          trControl = fitControl)

modelo_svmpoly


# Gráfico
ggplot(modelo_svmpoly) +
  labs(title = "Evolución del Accuracy del modelo SVMpolynomial") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```


```{r}
# Predicciones
svmpoly_predicciones = predict(modelo_svmpoly, newdata = dataset.test[1:(ncol(dataset.test)-1)], type = "raw")

# Evaluación
(mconfusion_svmpoly = confusionMatrix(svmpoly_predicciones, dataset.test$Clasificación))

```

```{r}
resultados_SVM_poly <- data.frame( Modelo        = "SVM-poly",
                              Parámetros    = "",
                              Accuracy      = round(mconfusion_svmpoly[["overall"]][["Accuracy"]], 3),
                              kappa         = round(mconfusion_svmpoly[["overall"]][["Kappa"]],3),
                              Error_clasificación = round((1-mconfusion_svmpoly[["overall"]][["Accuracy"]])*100,3),
                              AccuracyLower = round(mconfusion_svmpoly[["overall"]][["AccuracyLower"]],3),
                              AccuracyUpper = round(mconfusion_svmpoly[["overall"]][["AccuracyUpper"]],3)
                              )
resultados_SVM_poly
```




## 4.5 Árbol de decisión

### 4.5.1 Árbol de decisión sin boosting
```{r warning=FALSE, message=FALSE}
#Hiperparámetros
hiperparametros <- data.frame(parameter = "none")

# Ajuste del modelo
set.seed(29)
modelo_C5.0_sinhp <- train(Clasificación ~ ., data = dataset.train,
                     method = "C5.0Tree",
                     tuneGrid = hiperparametros,
                     metric = "Accuracy",
                     trControl = fitControl)
modelo_C5.0_sinhp

#summary(modelo_C5.0$finalModel)

# Predicciones
predicciones_C5.0_sinhp <- predict(modelo_C5.0_sinhp, dataset.test[1:(ncol(dataset.test)-1)])

# Evaluación
(mconfusion_arbol_sinhp <- confusionMatrix(data = predicciones_C5.0_sinhp, reference = dataset.test$Clasificación))

```


### 4.5.2 Árbol de decisión con boosting


```{r warning=FALSE, message=FALSE}
#Hiperparámetros
hiperparametros <- expand.grid(trials = c(10:40),
                               model = "tree",
                               winnow = c(FALSE))

# Ajuste del modelo
set.seed(29)
modelo_C5.0 <- train(Clasificación ~ ., data = dataset.train,
                     method = "C5.0",
                     tuneGrid = hiperparametros,
                     metric = "Accuracy",
                     trControl = fitControl)
modelo_C5.0

# Gráfico
ggplot(modelo_C5.0, highlight = TRUE) +
  labs(title = "Evolución del Accuracy del modelo C5.0") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

# Predicciones
predicciones_C5.0 <- predict(modelo_C5.0, dataset.test[1:(ncol(dataset.test)-1)])

# Evaluación
(mconfusion_arbol_b <- confusionMatrix(data = predicciones_C5.0, reference = dataset.test$Clasificación))

```


Comprobamos que el modelo con boosting presenta mejores resultados, que es el que nos quedaremos para comparar.

```{r}
resultados_arbol_b <- data.frame( Modelo        = "Árbol de decisión",
                              Parámetros    = "modelo= Boosting",
                              Accuracy      = round(mconfusion_arbol_b[["overall"]][["Accuracy"]], 3),
                              kappa         = round(mconfusion_arbol_b[["overall"]][["Kappa"]],3),
                              Error_clasificación = round((1-mconfusion_arbol_b[["overall"]][["Accuracy"]])*100,3),
                              AccuracyLower = round(mconfusion_arbol_b[["overall"]][["AccuracyLower"]],3),
                              AccuracyUpper = round(mconfusion_arbol_b[["overall"]][["AccuracyUpper"]],3)
                              )
resultados_arbol_b
```


## 4.6 Random Forest
Se explorará la opción de número de árboles n = 100, 200.


```{r warning=FALSE, message=FALSE}
# Hiperparámetros
hiperparametros <- expand.grid(mtry = c(1:5),
                               min.node.size = c(1,2,3,4,5),
                               splitrule = c("gini"))

# Ajuste del modelo
set.seed(29)
modelo_forest <- train(Clasificación ~ ., data = dataset.train,
                   method = "ranger",
                   tuneGrid = hiperparametros,
                   metric = "Accuracy",
                   trControl = fitControl,
                   # Número de árboles ajustados
                   num.trees = 500)
modelo_forest


# Gráfico
ggplot(modelo_forest) +
  labs(title = "Evolución del Accuracy del modelo Random Forest") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))


# Predicciones
predicciones_rf <- predict(modelo_forest, newdata = dataset.test, type = "raw")


# Evaluación
(mconfusion_forest <- confusionMatrix(data = predicciones_rf, reference = dataset.test$Clasificación))
```


```{r}
resultados_RF <- data.frame( Modelo        = "Random Forest",
                              Parámetros    = "ntree=200",
                              Accuracy      = round(mconfusion_forest[["overall"]][["Accuracy"]], 3),
                              kappa         = round(mconfusion_forest[["overall"]][["Kappa"]],3),
                              Error_clasificación = round((1-mconfusion_forest[["overall"]][["Accuracy"]])*100,3),
                              AccuracyLower = round(mconfusion_forest[["overall"]][["AccuracyLower"]],3),
                              AccuracyUpper = round(mconfusion_forest[["overall"]][["AccuracyUpper"]],3)
                              )
resultados_RF
```



# 5. Tabla resumen del rendimiento de los distintos modelos

```{r}
library(kableExtra)
tabla_resumen= rbind(resultados_knn,
                     resultados_NaiveBayes,
                     resultados_ann_caret,
                     resultados_ANN1,
                     resultados_ANN2, 
                     resultados_SVM_radial,
                     resultados_SVM_poly,
                     resultados_arbol_b, 
                     resultados_RF
                     )

#Establecemos el orden por valores de Accuracy
orden = order(tabla_resumen$Accuracy, decreasing = TRUE)
tabla_resumen_ordenada <- tabla_resumen[orden, ]

kable(tabla_resumen_ordenada, digits = 3, caption = "Rendimiento de los modelos")
```




Bibliografía: 

https://es.linkedin.com/pulse/clases-desbalanceadas-y-su-tratamiento-en-r-felipe-maggi
https://www.statology.org/smote-in-r/
https://sitiobigdata.com/2019/12/24/clasificacion-multiclase-con-aprendizaje-automatico/
https://tensorflow.rstudio.com/install/

ejemplos caret:
https://rpubs.com/Joaquin_AR/383283
